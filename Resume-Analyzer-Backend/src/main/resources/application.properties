spring.application.name=Resume-Analyzer-Backend
server.port=7681
langchain4j.open-ai.chat-model.api-key=ollama
langchain4j.open-ai.chat-model.base-url=http://localhost:11434/v1
langchain4j.open-ai.chat-model.model-name=llama3:latest
langchain4j.open-ai.chat-model.temperature=0.3
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
langchain4j.open-ai.chat-model.frequency-penalty=1.5

logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
